{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE # To handle class imbalance\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore') # Ignore warnings for cleaner output\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "ctm_bf5QDfEC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "try:\n",
        "    df = pd.read_csv('ola_driver_scaler.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    # Drop the 'Unnamed: 0' column if it exists\n",
        "    if 'Unnamed: 0' in df.columns:\n",
        "        df = df.drop(columns=['Unnamed: 0'])\n",
        "        print(\"Dropped 'Unnamed: 0' column.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: ola_driver_scaler.csv not found in the current directory.\")\n",
        "    exit() # Exit if the file is not found\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BtpUPtzpDzoG",
        "outputId": "11f8346c-97f4-47f6-9342-34034c23a875"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "Dropped 'Unnamed: 0' column.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initial EDA ---\n",
        "print(\"\\n--- Initial Exploratory Data Analysis ---\")\n",
        "\n",
        "# Display first 5 rows\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display shape\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "\n",
        "# Display data types and non-null counts\n",
        "print(\"\\nDataset info:\")\n",
        "df.info()\n",
        "\n",
        "# Display statistical summary for numerical features\n",
        "print(\"\\nStatistical summary (numerical features):\")\n",
        "print(df.describe())\n",
        "\n",
        "# Display statistical summary for object/categorical features (like MMMM-YY, City)\n",
        "print(\"\\nStatistical summary (categorical features):\")\n",
        "print(df.describe(include=['object']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JSjKRJHDETo8",
        "outputId": "702ccb2b-3eda-46fc-a0a9-dacbefd98acf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initial Exploratory Data Analysis ---\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "     MMM-YY  Driver_ID   Age  Gender City  Education_Level  Income  \\\n",
            "0  01/01/19          1  28.0     0.0  C23                2   57387   \n",
            "1  02/01/19          1  28.0     0.0  C23                2   57387   \n",
            "2  03/01/19          1  28.0     0.0  C23                2   57387   \n",
            "3  11/01/20          2  31.0     0.0   C7                2   67016   \n",
            "4  12/01/20          2  31.0     0.0   C7                2   67016   \n",
            "\n",
            "  Dateofjoining LastWorkingDate  Joining Designation  Grade  \\\n",
            "0      24/12/18             NaN                    1      1   \n",
            "1      24/12/18             NaN                    1      1   \n",
            "2      24/12/18        03/11/19                    1      1   \n",
            "3      11/06/20             NaN                    2      2   \n",
            "4      11/06/20             NaN                    2      2   \n",
            "\n",
            "   Total Business Value  Quarterly Rating  \n",
            "0               2381060                 2  \n",
            "1               -665480                 2  \n",
            "2                     0                 2  \n",
            "3                     0                 1  \n",
            "4                     0                 1  \n",
            "\n",
            "Dataset shape: (19104, 13)\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19104 entries, 0 to 19103\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   MMM-YY                19104 non-null  object \n",
            " 1   Driver_ID             19104 non-null  int64  \n",
            " 2   Age                   19043 non-null  float64\n",
            " 3   Gender                19052 non-null  float64\n",
            " 4   City                  19104 non-null  object \n",
            " 5   Education_Level       19104 non-null  int64  \n",
            " 6   Income                19104 non-null  int64  \n",
            " 7   Dateofjoining         19104 non-null  object \n",
            " 8   LastWorkingDate       1616 non-null   object \n",
            " 9   Joining Designation   19104 non-null  int64  \n",
            " 10  Grade                 19104 non-null  int64  \n",
            " 11  Total Business Value  19104 non-null  int64  \n",
            " 12  Quarterly Rating      19104 non-null  int64  \n",
            "dtypes: float64(2), int64(7), object(4)\n",
            "memory usage: 1.9+ MB\n",
            "\n",
            "Statistical summary (numerical features):\n",
            "          Driver_ID           Age        Gender  Education_Level  \\\n",
            "count  19104.000000  19043.000000  19052.000000     19104.000000   \n",
            "mean    1415.591133     34.668435      0.418749         1.021671   \n",
            "std      810.705321      6.257912      0.493367         0.800167   \n",
            "min        1.000000     21.000000      0.000000         0.000000   \n",
            "25%      710.000000     30.000000      0.000000         0.000000   \n",
            "50%     1417.000000     34.000000      0.000000         1.000000   \n",
            "75%     2137.000000     39.000000      1.000000         2.000000   \n",
            "max     2788.000000     58.000000      1.000000         2.000000   \n",
            "\n",
            "              Income  Joining Designation         Grade  Total Business Value  \\\n",
            "count   19104.000000         19104.000000  19104.000000          1.910400e+04   \n",
            "mean    65652.025126             1.690536      2.252670          5.716621e+05   \n",
            "std     30914.515344             0.836984      1.026512          1.128312e+06   \n",
            "min     10747.000000             1.000000      1.000000         -6.000000e+06   \n",
            "25%     42383.000000             1.000000      1.000000          0.000000e+00   \n",
            "50%     60087.000000             1.000000      2.000000          2.500000e+05   \n",
            "75%     83969.000000             2.000000      3.000000          6.997000e+05   \n",
            "max    188418.000000             5.000000      5.000000          3.374772e+07   \n",
            "\n",
            "       Quarterly Rating  \n",
            "count      19104.000000  \n",
            "mean           2.008899  \n",
            "std            1.009832  \n",
            "min            1.000000  \n",
            "25%            1.000000  \n",
            "50%            2.000000  \n",
            "75%            3.000000  \n",
            "max            4.000000  \n",
            "\n",
            "Statistical summary (categorical features):\n",
            "          MMM-YY   City Dateofjoining LastWorkingDate\n",
            "count      19104  19104         19104            1616\n",
            "unique        24     29           869             493\n",
            "top     01/01/19    C20      23/07/15        29/07/20\n",
            "freq        1022   1008           192              70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Cleaning & Preprocessing ---\n",
        "print(\"\\n--- Data Cleaning & Preprocessing ---\")\n",
        "\n",
        "# Convert date columns to datetime objects\n",
        "print(\"\\nConverting date columns...\")\n",
        "# Corrected column name 'MMM-YY'\n",
        "try:\n",
        "    # Try parsing with day first (e.g., 01/01/19)\n",
        "    df['MMM-YY'] = pd.to_datetime(df['MMM-YY'], format='%d/%m/%y', errors='coerce')\n",
        "except Exception as e1:\n",
        "    print(f\"Initial date parsing failed: {e1}. Trying alternative formats.\")\n",
        "    try:\n",
        "        # Fallback format if needed (e.g., Jan-19) - adjust based on actual data if first fails\n",
        "        df['MMM-YY'] = pd.to_datetime(df['MMM-YY'], format='%b-%y', errors='coerce')\n",
        "    except Exception as e2:\n",
        "         print(f\"Error converting 'MMM-YY': {e2}. Please check the date format.\")\n",
        "         # Consider exiting or handling this case based on requirements\n",
        "\n",
        "# Corrected column name 'Dateofjoining' and added dayfirst=False for common formats like MM/DD/YY\n",
        "df['Dateofjoining'] = pd.to_datetime(df['Dateofjoining'], errors='coerce', dayfirst=False)\n",
        "df['LastWorkingDate'] = pd.to_datetime(df['LastWorkingDate'], errors='coerce', dayfirst=False)\n",
        "print(\"Date columns converted (attempted).\")\n",
        "print(\"\\nData types after date conversion:\")\n",
        "df.info() # Display info again to show converted types\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tyae29HeEid4",
        "outputId": "3c53b185-d0ab-4cc1-fe80-62568c64f554"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Cleaning & Preprocessing ---\n",
            "\n",
            "Converting date columns...\n",
            "Date columns converted (attempted).\n",
            "\n",
            "Data types after date conversion:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19104 entries, 0 to 19103\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   MMM-YY                19104 non-null  datetime64[ns]\n",
            " 1   Driver_ID             19104 non-null  int64         \n",
            " 2   Age                   19043 non-null  float64       \n",
            " 3   Gender                19052 non-null  float64       \n",
            " 4   City                  19104 non-null  object        \n",
            " 5   Education_Level       19104 non-null  int64         \n",
            " 6   Income                19104 non-null  int64         \n",
            " 7   Dateofjoining         19104 non-null  datetime64[ns]\n",
            " 8   LastWorkingDate       1616 non-null   datetime64[ns]\n",
            " 9   Joining Designation   19104 non-null  int64         \n",
            " 10  Grade                 19104 non-null  int64         \n",
            " 11  Total Business Value  19104 non-null  int64         \n",
            " 12  Quarterly Rating      19104 non-null  int64         \n",
            "dtypes: datetime64[ns](3), float64(2), int64(7), object(1)\n",
            "memory usage: 1.9+ MB\n",
            "\n",
            "Missing values per column:\n",
            "MMM-YY                      0\n",
            "Driver_ID                   0\n",
            "Age                        61\n",
            "Gender                     52\n",
            "City                        0\n",
            "Education_Level             0\n",
            "Income                      0\n",
            "Dateofjoining               0\n",
            "LastWorkingDate         17488\n",
            "Joining Designation         0\n",
            "Grade                       0\n",
            "Total Business Value        0\n",
            "Quarterly Rating            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KNN Imputation ---\n",
        "print(\"\\n--- KNN Imputation for Missing Numerical Values ---\")\n",
        "\n",
        "# Identify numerical columns for imputation (excluding Driver_ID and potentially target-related later)\n",
        "# Based on typical datasets and the info() output, these are likely candidates.\n",
        "# We'll refine this list based on the actual isnull().sum() output when the script runs.\n",
        "numerical_cols_for_imputation = ['Age', 'Income', 'Total Business Value', 'Quarterly Rating']\n",
        "\n",
        "# Filter out columns that might not exist or have no missing values to avoid errors\n",
        "numerical_cols_to_impute = [col for col in numerical_cols_for_imputation if col in df.columns and df[col].isnull().any()]\n",
        "\n",
        "if not numerical_cols_to_impute:\n",
        "    print(\"No missing values found in the selected numerical columns for imputation.\")\n",
        "else:\n",
        "    print(f\"Performing KNN Imputation on: {numerical_cols_to_impute}\")\n",
        "    # Select only the numerical columns for the imputer\n",
        "    imputer_data = df[numerical_cols_to_impute]\n",
        "\n",
        "    # Initialize KNNImputer (using default n_neighbors=5)\n",
        "    knn_imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "    # Fit and transform the data\n",
        "    imputed_data = knn_imputer.fit_transform(imputer_data)\n",
        "\n",
        "    # Convert the imputed data back to a DataFrame with original column names\n",
        "    imputed_df = pd.DataFrame(imputed_data, columns=numerical_cols_to_impute, index=df.index)\n",
        "\n",
        "    # Update the original DataFrame with imputed values\n",
        "    df.update(imputed_df)\n",
        "\n",
        "    print(\"KNN Imputation completed.\")\n",
        "    print(\"\\nMissing values after KNN Imputation:\")\n",
        "    print(df[numerical_cols_to_impute].isnull().sum()) # Verify imputation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1EnXEMPCEmcT",
        "outputId": "5db6b5c3-5d64-46d7-ef4a-b885c02fc714"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- KNN Imputation for Missing Numerical Values ---\n",
            "Performing KNN Imputation on: ['Age']\n",
            "KNN Imputation completed.\n",
            "\n",
            "Missing values after KNN Imputation:\n",
            "Age    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Aggregation ---\n",
        "print(\"\\n--- Aggregating Data by Driver_ID ---\")\n",
        "\n",
        "# Sort by Driver_ID and reporting date to ensure 'last' picks the latest record\n",
        "# Corrected column name 'MMM-YY'\n",
        "df = df.sort_values(by=['Driver_ID', 'MMM-YY'])\n",
        "\n",
        "# Define aggregation dictionary\n",
        "agg_dict = {\n",
        "    # Static features: take the last known value\n",
        "    'Age': 'last',\n",
        "    'Gender': 'last',\n",
        "    'City': 'last',\n",
        "    'Education_Level': 'last',\n",
        "    # Corrected column name 'Dateofjoining'\n",
        "    'Dateofjoining': 'last',\n",
        "    'Joining Designation': 'last',\n",
        "    # Time-varying features:\n",
        "    'Income': ['mean', 'last'], # Keep mean income and last recorded income\n",
        "    'Grade': 'last', # Last known grade\n",
        "    'Total Business Value': ['mean', 'last'], # Keep mean and last business value\n",
        "    'Quarterly Rating': ['first', 'last'], # Keep first and last rating for comparison later\n",
        "    # Date features:\n",
        "    # Corrected column name 'MMM-YY'\n",
        "    'MMM-YY': 'max', # Last reporting month\n",
        "    'LastWorkingDate': 'max' # Last working date (will be NaT if still working)\n",
        "}\n",
        "\n",
        "# Perform aggregation\n",
        "df_agg = df.groupby('Driver_ID').agg(agg_dict)\n",
        "\n",
        "# Flatten MultiIndex columns (e.g., ('Income', 'mean') becomes 'Income_mean')\n",
        "df_agg.columns = ['_'.join(col).strip('_') for col in df_agg.columns.values]\n",
        "\n",
        "# Reset index to bring Driver_ID back as a column\n",
        "df_agg = df_agg.reset_index()\n",
        "\n",
        "# Rename columns by removing '_last' suffix for clarity\n",
        "df_agg.columns = [col.replace('_last', '') if col.endswith('_last') else col for col in df_agg.columns]\n",
        "# Also remove '_max' suffix from date columns used for tenure/target\n",
        "df_agg.columns = [col.replace('_max', '') if col.endswith('_max') else col for col in df_agg.columns]\n",
        "# Rename Quarterly Rating_first if it exists (used for rating_increase)\n",
        "if 'Quarterly Rating_first' in df_agg.columns:\n",
        "     df_agg = df_agg.rename(columns={'Quarterly Rating_first': 'Quarterly_Rating_first'})\n",
        "\n",
        "\n",
        "print(\"Data aggregated successfully.\")\n",
        "print(f\"Aggregated dataset shape: {df_agg.shape}\")\n",
        "print(\"\\nFirst 5 rows of aggregated data:\")\n",
        "print(df_agg.head())\n",
        "print(\"\\nAggregated data info:\")\n",
        "df_agg.info()\n",
        "print(\"\\nMissing values in aggregated data:\")\n",
        "print(df_agg.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t_aMkVB2EomQ",
        "outputId": "d9b541e7-e19a-4a35-faca-83469fae39b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Aggregating Data by Driver_ID ---\n",
            "Data aggregated successfully.\n",
            "Aggregated dataset shape: (2381, 16)\n",
            "\n",
            "First 5 rows of aggregated data:\n",
            "   Driver_ID   Age  Gender City  Education_Level Dateofjoining  \\\n",
            "0          1  28.0     0.0  C23                2    2018-12-24   \n",
            "1          2  31.0     0.0   C7                2    2020-11-06   \n",
            "2          4  43.0     0.0  C13                2    2019-12-07   \n",
            "3          5  29.0     0.0   C9                0    2019-01-09   \n",
            "4          6  31.0     1.0  C11                1    2020-07-31   \n",
            "\n",
            "   Joining Designation  Income_mean  Income  Grade  Total Business Value_mean  \\\n",
            "0                    1      57387.0   57387      1                   571860.0   \n",
            "1                    2      67016.0   67016      2                        0.0   \n",
            "2                    2      65603.0   65603      2                    70000.0   \n",
            "3                    1      46368.0   46368      1                    40120.0   \n",
            "4                    3      78728.0   78728      3                   253000.0   \n",
            "\n",
            "   Total Business Value  Quarterly_Rating_first  Quarterly Rating     MMM-YY  \\\n",
            "0                     0                       2                 2 2019-01-03   \n",
            "1                     0                       1                 1 2020-01-12   \n",
            "2                     0                       1                 1 2020-01-04   \n",
            "3                     0                       1                 1 2019-01-03   \n",
            "4                     0                       1                 2 2020-01-12   \n",
            "\n",
            "  LastWorkingDate  \n",
            "0      2019-03-11  \n",
            "1             NaT  \n",
            "2      2020-04-27  \n",
            "3      2019-03-07  \n",
            "4             NaT  \n",
            "\n",
            "Aggregated data info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2381 entries, 0 to 2380\n",
            "Data columns (total 16 columns):\n",
            " #   Column                     Non-Null Count  Dtype         \n",
            "---  ------                     --------------  -----         \n",
            " 0   Driver_ID                  2381 non-null   int64         \n",
            " 1   Age                        2381 non-null   float64       \n",
            " 2   Gender                     2381 non-null   float64       \n",
            " 3   City                       2381 non-null   object        \n",
            " 4   Education_Level            2381 non-null   int64         \n",
            " 5   Dateofjoining              2381 non-null   datetime64[ns]\n",
            " 6   Joining Designation        2381 non-null   int64         \n",
            " 7   Income_mean                2381 non-null   float64       \n",
            " 8   Income                     2381 non-null   int64         \n",
            " 9   Grade                      2381 non-null   int64         \n",
            " 10  Total Business Value_mean  2381 non-null   float64       \n",
            " 11  Total Business Value       2381 non-null   int64         \n",
            " 12  Quarterly_Rating_first     2381 non-null   int64         \n",
            " 13  Quarterly Rating           2381 non-null   int64         \n",
            " 14  MMM-YY                     2381 non-null   datetime64[ns]\n",
            " 15  LastWorkingDate            1616 non-null   datetime64[ns]\n",
            "dtypes: datetime64[ns](3), float64(4), int64(8), object(1)\n",
            "memory usage: 297.8+ KB\n",
            "\n",
            "Missing values in aggregated data:\n",
            "Driver_ID                      0\n",
            "Age                            0\n",
            "Gender                         0\n",
            "City                           0\n",
            "Education_Level                0\n",
            "Dateofjoining                  0\n",
            "Joining Designation            0\n",
            "Income_mean                    0\n",
            "Income                         0\n",
            "Grade                          0\n",
            "Total Business Value_mean      0\n",
            "Total Business Value           0\n",
            "Quarterly_Rating_first         0\n",
            "Quarterly Rating               0\n",
            "MMM-YY                         0\n",
            "LastWorkingDate              765\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Feature Engineering ---\n",
        "print(\"\\n--- Feature Engineering ---\")\n",
        "\n",
        "# 1. Target Variable: 1 if driver left, 0 otherwise\n",
        "# Uses the renamed 'LastWorkingDate' column\n",
        "df_agg['target'] = df_agg['LastWorkingDate'].notna().astype(int)\n",
        "print(f\"\\nTarget variable 'target' created. Distribution:\\n{df_agg['target'].value_counts(normalize=True)}\")\n",
        "\n",
        "# 2. Quarterly Rating Increase: 1 if last rating > first rating\n",
        "# Ensure both columns exist before creating the feature (using renamed columns)\n",
        "if 'Quarterly_Rating_first' in df_agg.columns and 'Quarterly_Rating' in df_agg.columns:\n",
        "    df_agg['rating_increase'] = (df_agg['Quarterly_Rating'] > df_agg['Quarterly_Rating_first']).astype(int)\n",
        "    print(\"\\nFeature 'rating_increase' created.\")\n",
        "    # Drop the original first rating column as it's now captured in rating_increase\n",
        "    df_agg = df_agg.drop(columns=['Quarterly_Rating_first'])\n",
        "else:\n",
        "    print(\"\\nWarning: 'Quarterly_Rating_first' or 'Quarterly_Rating' not found after aggregation/renaming. Skipping 'rating_increase' feature.\")\n",
        "\n",
        "\n",
        "# 3. Monthly Income Increase (Proxy): 1 if last income > mean income\n",
        "# Ensure both columns exist\n",
        "if 'Income_mean' in df_agg.columns and 'Income_last' in df_agg.columns:\n",
        "    df_agg['income_increase_over_mean'] = (df_agg['Income_last'] > df_agg['Income_mean']).astype(int)\n",
        "    print(\"Feature 'income_increase_over_mean' created.\")\n",
        "    # Decide whether to keep Income_mean and Income_last or just one. Let's keep both for now.\n",
        "else:\n",
        "     print(\"\\nWarning: 'Income_mean' or 'Income_last' not found. Skipping 'income_increase_over_mean' feature.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zBtjMyv7E1jg",
        "outputId": "58e8a7a8-97d9-4665-befc-8296fb631c42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Feature Engineering ---\n",
            "\n",
            "Target variable 'target' created. Distribution:\n",
            "target\n",
            "1    0.678706\n",
            "0    0.321294\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Warning: 'Quarterly_Rating_first' or 'Quarterly_Rating' not found after aggregation/renaming. Skipping 'rating_increase' feature.\n",
            "\n",
            "Warning: 'Income_mean' or 'Income_last' not found. Skipping 'income_increase_over_mean' feature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Tenure: Calculate tenure in days\n",
        "# Ensure required date columns exist (using renamed columns)\n",
        "if 'Dateofjoining' in df_agg.columns and 'LastWorkingDate' in df_agg.columns and 'MMM-YY' in df_agg.columns:\n",
        "    # For drivers who left\n",
        "    left_mask = df_agg['target'] == 1\n",
        "    df_agg.loc[left_mask, 'tenure_days'] = (df_agg['LastWorkingDate'] - df_agg['Dateofjoining']).dt.days\n",
        "\n",
        "    # For drivers still working (use last reporting date)\n",
        "    working_mask = df_agg['target'] == 0\n",
        "    df_agg.loc[working_mask, 'tenure_days'] = (df_agg['MMM-YY'] - df_agg['Dateofjoining']).dt.days\n",
        "\n",
        "    # Handle potential negative tenure if dates are inconsistent (e.g., joining date after last working date)\n",
        "    df_agg['tenure_days'] = df_agg['tenure_days'].apply(lambda x: max(x, 0) if pd.notna(x) else 0)\n",
        "    # Handle potential negative tenure if dates are inconsistent\n",
        "    df_agg['tenure_days'] = df_agg['tenure_days'].apply(lambda x: max(x, 0) if pd.notna(x) else 0)\n",
        "    # Fill any remaining NaNs in tenure_days (e.g., if Dateofjoining was NaT) with 0\n",
        "    df_agg['tenure_days'] = df_agg['tenure_days'].fillna(0)\n",
        "    print(\"Feature 'tenure_days' created.\")\n",
        "\n",
        "    # Drop original date columns used for tenure calculation (using renamed columns)\n",
        "    df_agg = df_agg.drop(columns=['Dateofjoining', 'LastWorkingDate', 'MMM-YY'])\n",
        "else:\n",
        "    print(\"\\nWarning: Required date columns ('Dateofjoining', 'LastWorkingDate', 'MMM-YY') for tenure calculation not found after aggregation/renaming. Skipping 'tenure_days' feature.\")\n",
        "\n",
        "\n",
        "print(\"\\nData after Feature Engineering:\")\n",
        "print(df_agg.head())\n",
        "print(\"\\nInfo after Feature Engineering:\")\n",
        "df_agg.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cgaaV6bnE6YC",
        "outputId": "19959e97-3c35-429e-ff18-56a12743f9f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'tenure_days' created.\n",
            "\n",
            "Data after Feature Engineering:\n",
            "   Driver_ID   Age  Gender City  Education_Level  Joining Designation  \\\n",
            "0          1  28.0     0.0  C23                2                    1   \n",
            "1          2  31.0     0.0   C7                2                    2   \n",
            "2          4  43.0     0.0  C13                2                    2   \n",
            "3          5  29.0     0.0   C9                0                    1   \n",
            "4          6  31.0     1.0  C11                1                    3   \n",
            "\n",
            "   Income_mean  Income  Grade  Total Business Value_mean  \\\n",
            "0      57387.0   57387      1                   571860.0   \n",
            "1      67016.0   67016      2                        0.0   \n",
            "2      65603.0   65603      2                    70000.0   \n",
            "3      46368.0   46368      1                    40120.0   \n",
            "4      78728.0   78728      3                   253000.0   \n",
            "\n",
            "   Total Business Value  Quarterly_Rating_first  Quarterly Rating  target  \\\n",
            "0                     0                       2                 2       1   \n",
            "1                     0                       1                 1       0   \n",
            "2                     0                       1                 1       1   \n",
            "3                     0                       1                 1       1   \n",
            "4                     0                       1                 2       0   \n",
            "\n",
            "   tenure_days  \n",
            "0         77.0  \n",
            "1          0.0  \n",
            "2        142.0  \n",
            "3         57.0  \n",
            "4          0.0  \n",
            "\n",
            "Info after Feature Engineering:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2381 entries, 0 to 2380\n",
            "Data columns (total 15 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Driver_ID                  2381 non-null   int64  \n",
            " 1   Age                        2381 non-null   float64\n",
            " 2   Gender                     2381 non-null   float64\n",
            " 3   City                       2381 non-null   object \n",
            " 4   Education_Level            2381 non-null   int64  \n",
            " 5   Joining Designation        2381 non-null   int64  \n",
            " 6   Income_mean                2381 non-null   float64\n",
            " 7   Income                     2381 non-null   int64  \n",
            " 8   Grade                      2381 non-null   int64  \n",
            " 9   Total Business Value_mean  2381 non-null   float64\n",
            " 10  Total Business Value       2381 non-null   int64  \n",
            " 11  Quarterly_Rating_first     2381 non-null   int64  \n",
            " 12  Quarterly Rating           2381 non-null   int64  \n",
            " 13  target                     2381 non-null   int64  \n",
            " 14  tenure_days                2381 non-null   float64\n",
            "dtypes: float64(5), int64(9), object(1)\n",
            "memory usage: 279.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Further EDA on Aggregated Data ---\n",
        "print(\"\\n--- Further EDA on Aggregated Data ---\")\n",
        "\n",
        "# Statistical summary of the final aggregated dataset\n",
        "print(\"\\nStatistical summary of aggregated data:\")\n",
        "# Include 'all' to get summary for both numerical and categorical (if any remain as object)\n",
        "print(df_agg.describe(include='all'))\n",
        "\n",
        "# Correlation Analysis\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "# Select only numerical columns for correlation calculation\n",
        "numerical_cols = df_agg.select_dtypes(include=np.number).columns\n",
        "# Exclude Driver_ID from correlation matrix if it's numerical\n",
        "if 'Driver_ID' in numerical_cols:\n",
        "    numerical_cols = numerical_cols.drop('Driver_ID')\n",
        "\n",
        "correlation_matrix = df_agg[numerical_cols].corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize correlation matrix and save to file\n",
        "plt.figure(figsize=(15, 12)) # Increased size for more features\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm') # Annot=False if too cluttered\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png')\n",
        "print(\"\\nCorrelation heatmap saved to correlation_heatmap.png\")\n",
        "plt.close() # Close the plot to free memory\n",
        "\n",
        "print(\"\\nTarget variable distribution:\")\n",
        "print(df_agg['target'].value_counts())\n",
        "print(df_agg['target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xlMT_15fE-vx",
        "outputId": "29048a46-6bbc-4574-8916-9dd0024a2834"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Further EDA on Aggregated Data ---\n",
            "\n",
            "Statistical summary of aggregated data:\n",
            "          Driver_ID          Age       Gender  City  Education_Level  \\\n",
            "count   2381.000000  2381.000000  2381.000000  2381       2381.00000   \n",
            "unique          NaN          NaN          NaN    29              NaN   \n",
            "top             NaN          NaN          NaN   C20              NaN   \n",
            "freq            NaN          NaN          NaN   152              NaN   \n",
            "mean    1397.559009    33.686551     0.410332   NaN          1.00756   \n",
            "std      806.161628     5.968622     0.491997   NaN          0.81629   \n",
            "min        1.000000    21.000000     0.000000   NaN          0.00000   \n",
            "25%      695.000000    29.000000     0.000000   NaN          0.00000   \n",
            "50%     1400.000000    33.000000     0.000000   NaN          1.00000   \n",
            "75%     2100.000000    37.000000     1.000000   NaN          2.00000   \n",
            "max     2788.000000    58.000000     1.000000   NaN          2.00000   \n",
            "\n",
            "        Joining Designation    Income_mean         Income        Grade  \\\n",
            "count           2381.000000    2381.000000    2381.000000  2381.000000   \n",
            "unique                  NaN            NaN            NaN          NaN   \n",
            "top                     NaN            NaN            NaN          NaN   \n",
            "freq                    NaN            NaN            NaN          NaN   \n",
            "mean               1.820244   59232.460484   59334.157077     2.096598   \n",
            "std                0.841433   28298.214012   28383.666384     0.941522   \n",
            "min                1.000000   10747.000000   10747.000000     1.000000   \n",
            "25%                1.000000   39104.000000   39104.000000     1.000000   \n",
            "50%                2.000000   55285.000000   55315.000000     2.000000   \n",
            "75%                2.000000   75835.000000   75986.000000     3.000000   \n",
            "max                5.000000  188418.000000  188418.000000     5.000000   \n",
            "\n",
            "        Total Business Value_mean  Total Business Value  \\\n",
            "count                2.381000e+03          2.381000e+03   \n",
            "unique                        NaN                   NaN   \n",
            "top                           NaN                   NaN   \n",
            "freq                          NaN                   NaN   \n",
            "mean                 3.120854e+05          2.667694e+05   \n",
            "std                  4.495705e+05          1.134681e+06   \n",
            "min                 -1.979329e+05         -9.900000e+05   \n",
            "25%                  0.000000e+00          0.000000e+00   \n",
            "50%                  1.506244e+05          0.000000e+00   \n",
            "75%                  4.294988e+05          1.969200e+05   \n",
            "max                  3.972128e+06          3.374772e+07   \n",
            "\n",
            "        Quarterly_Rating_first  Quarterly Rating       target  tenure_days  \n",
            "count              2381.000000       2381.000000  2381.000000  2381.000000  \n",
            "unique                     NaN               NaN          NaN          NaN  \n",
            "top                        NaN               NaN          NaN          NaN  \n",
            "freq                       NaN               NaN          NaN          NaN  \n",
            "mean                  1.486350          1.427971     0.678706   363.968501  \n",
            "std                   0.834348          0.809839     0.467071   521.767726  \n",
            "min                   1.000000          1.000000     0.000000     0.000000  \n",
            "25%                   1.000000          1.000000     0.000000    52.000000  \n",
            "50%                   1.000000          1.000000     1.000000   147.000000  \n",
            "75%                   2.000000          2.000000     1.000000   419.000000  \n",
            "max                   4.000000          4.000000     1.000000  2582.000000  \n",
            "\n",
            "Correlation matrix:\n",
            "                                Age    Gender  Education_Level  \\\n",
            "Age                        1.000000  0.031799        -0.007936   \n",
            "Gender                     0.031799  1.000000        -0.008773   \n",
            "Education_Level           -0.007936 -0.008773         1.000000   \n",
            "Joining Designation        0.079186 -0.046056         0.003203   \n",
            "Income_mean                0.206020  0.006881         0.140779   \n",
            "Income                     0.208797  0.007451         0.140189   \n",
            "Grade                      0.250057 -0.003062        -0.017352   \n",
            "Total Business Value_mean  0.240927  0.009939         0.008085   \n",
            "Total Business Value       0.095507  0.013900        -0.018734   \n",
            "Quarterly_Rating_first     0.206374 -0.014498         0.038401   \n",
            "Quarterly Rating           0.150331  0.024119         0.006544   \n",
            "target                    -0.078543  0.008966        -0.007953   \n",
            "tenure_days                0.303591  0.022991         0.006027   \n",
            "\n",
            "                           Joining Designation  Income_mean    Income  \\\n",
            "Age                                   0.079186     0.206020  0.208797   \n",
            "Gender                               -0.046056     0.006881  0.007451   \n",
            "Education_Level                       0.003203     0.140779  0.140189   \n",
            "Joining Designation                   1.000000     0.484116  0.480523   \n",
            "Income_mean                           0.484116     1.000000  0.999620   \n",
            "Income                                0.480523     0.999620  1.000000   \n",
            "Grade                                 0.712459     0.739181  0.741453   \n",
            "Total Business Value_mean            -0.078550     0.379721  0.388510   \n",
            "Total Business Value                  0.025054     0.187926  0.190941   \n",
            "Quarterly_Rating_first               -0.282392     0.124521  0.131138   \n",
            "Quarterly Rating                     -0.063404     0.157654  0.163429   \n",
            "target                               -0.127773    -0.197988 -0.201935   \n",
            "tenure_days                          -0.231794     0.302497  0.304633   \n",
            "\n",
            "                              Grade  Total Business Value_mean  \\\n",
            "Age                        0.250057                   0.240927   \n",
            "Gender                    -0.003062                   0.009939   \n",
            "Education_Level           -0.017352                   0.008085   \n",
            "Joining Designation        0.712459                  -0.078550   \n",
            "Income_mean                0.739181                   0.379721   \n",
            "Income                     0.741453                   0.388510   \n",
            "Grade                      1.000000                   0.370039   \n",
            "Total Business Value_mean  0.370039                   1.000000   \n",
            "Total Business Value       0.228364                   0.530212   \n",
            "Quarterly_Rating_first     0.039655                   0.654059   \n",
            "Quarterly Rating           0.120442                   0.593640   \n",
            "target                    -0.225585                  -0.329640   \n",
            "tenure_days                0.310143                   0.510418   \n",
            "\n",
            "                           Total Business Value  Quarterly_Rating_first  \\\n",
            "Age                                    0.095507                0.206374   \n",
            "Gender                                 0.013900               -0.014498   \n",
            "Education_Level                       -0.018734                0.038401   \n",
            "Joining Designation                    0.025054               -0.282392   \n",
            "Income_mean                            0.187926                0.124521   \n",
            "Income                                 0.190941                0.131138   \n",
            "Grade                                  0.228364                0.039655   \n",
            "Total Business Value_mean              0.530212                0.654059   \n",
            "Total Business Value                   1.000000                0.186975   \n",
            "Quarterly_Rating_first                 0.186975                1.000000   \n",
            "Quarterly Rating                       0.453893                0.355324   \n",
            "target                                -0.289008               -0.119616   \n",
            "tenure_days                            0.205761                0.481332   \n",
            "\n",
            "                           Quarterly Rating    target  tenure_days  \n",
            "Age                                0.150331 -0.078543     0.303591  \n",
            "Gender                             0.024119  0.008966     0.022991  \n",
            "Education_Level                    0.006544 -0.007953     0.006027  \n",
            "Joining Designation               -0.063404 -0.127773    -0.231794  \n",
            "Income_mean                        0.157654 -0.197988     0.302497  \n",
            "Income                             0.163429 -0.201935     0.304633  \n",
            "Grade                              0.120442 -0.225585     0.310143  \n",
            "Total Business Value_mean          0.593640 -0.329640     0.510418  \n",
            "Total Business Value               0.453893 -0.289008     0.205761  \n",
            "Quarterly_Rating_first             0.355324 -0.119616     0.481332  \n",
            "Quarterly Rating                   1.000000 -0.510532     0.223393  \n",
            "target                            -0.510532  1.000000    -0.017817  \n",
            "tenure_days                        0.223393 -0.017817     1.000000  \n",
            "\n",
            "Correlation heatmap saved to correlation_heatmap.png\n",
            "\n",
            "Target variable distribution:\n",
            "target\n",
            "1    1616\n",
            "0     765\n",
            "Name: count, dtype: int64\n",
            "target\n",
            "1    0.678706\n",
            "0    0.321294\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Encoding Categorical Variables ---\n",
        "print(\"\\n--- Encoding Categorical Variables ---\")\n",
        "\n",
        "# Identify categorical columns (object or category dtype)\n",
        "categorical_cols = df_agg.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Exclude Driver_ID if it was read as object, though it should be numerical\n",
        "if 'Driver_ID' in categorical_cols:\n",
        "    categorical_cols = categorical_cols.drop('Driver_ID')\n",
        "\n",
        "if len(categorical_cols) > 0:\n",
        "    print(f\"Applying One-Hot Encoding to: {list(categorical_cols)}\")\n",
        "    # Apply one-hot encoding\n",
        "    df_encoded = pd.get_dummies(df_agg, columns=categorical_cols, drop_first=True) # drop_first=True to avoid multicollinearity\n",
        "\n",
        "    print(\"Categorical variables encoded.\")\n",
        "    print(f\"Shape after encoding: {df_encoded.shape}\")\n",
        "    print(\"\\nColumns after encoding:\")\n",
        "    print(df_encoded.columns)\n",
        "\n",
        "    # Update df_agg to the encoded version\n",
        "    df_agg = df_encoded\n",
        "\n",
        "    # Ensure dummy columns are integer type\n",
        "    dummy_cols = [col for col in df_agg.columns if col.startswith(tuple(categorical_cols))]\n",
        "    for col in dummy_cols:\n",
        "        if df_agg[col].dtype not in [np.int64, np.int32, np.uint8, np.float64, np.float32]:\n",
        "             df_agg[col] = df_agg[col].astype(int)\n",
        "    print(\"Ensured dummy columns are integer type.\")\n",
        "\n",
        "else:\n",
        "    print(\"No categorical columns found to encode.\")\n",
        "\n",
        "# Datetime columns should have been dropped during tenure calculation now\n",
        "# Ensure City_last (original categorical column before dummifying) is dropped if it still exists\n",
        "if 'City' in df_agg.columns:\n",
        "     df_agg = df_agg.drop(columns=['City'], errors='ignore')\n",
        "     print(\"Dropped original 'City' column.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h-_U2cgUFDQa",
        "outputId": "5a5bd062-c78a-43f2-b75d-65cd853dc287"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Encoding Categorical Variables ---\n",
            "Applying One-Hot Encoding to: ['City']\n",
            "Categorical variables encoded.\n",
            "Shape after encoding: (2381, 42)\n",
            "\n",
            "Columns after encoding:\n",
            "Index(['Driver_ID', 'Age', 'Gender', 'Education_Level', 'Joining Designation',\n",
            "       'Income_mean', 'Income', 'Grade', 'Total Business Value_mean',\n",
            "       'Total Business Value', 'Quarterly_Rating_first', 'Quarterly Rating',\n",
            "       'target', 'tenure_days', 'City_C10', 'City_C11', 'City_C12', 'City_C13',\n",
            "       'City_C14', 'City_C15', 'City_C16', 'City_C17', 'City_C18', 'City_C19',\n",
            "       'City_C2', 'City_C20', 'City_C21', 'City_C22', 'City_C23', 'City_C24',\n",
            "       'City_C25', 'City_C26', 'City_C27', 'City_C28', 'City_C29', 'City_C3',\n",
            "       'City_C4', 'City_C5', 'City_C6', 'City_C7', 'City_C8', 'City_C9'],\n",
            "      dtype='object')\n",
            "Ensured dummy columns are integer type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final check for any remaining NaN values before splitting\n",
        "print(\"\\nChecking for NaN values before splitting:\")\n",
        "nan_check = df_agg.isnull().sum()\n",
        "print(nan_check[nan_check > 0])\n",
        "\n",
        "# If there are NaNs in numerical columns, fill with median\n",
        "numerical_cols_final = df_agg.select_dtypes(include=np.number).columns\n",
        "if 'Driver_ID' in numerical_cols_final:\n",
        "    numerical_cols_final = numerical_cols_final.drop(['Driver_ID', 'target'], errors='ignore') # Exclude ID and target\n",
        "else:\n",
        "     numerical_cols_final = numerical_cols_final.drop(['target'], errors='ignore')\n",
        "\n",
        "for col in numerical_cols_final:\n",
        "    if df_agg[col].isnull().any():\n",
        "        median_val = df_agg[col].median()\n",
        "        df_agg[col] = df_agg[col].fillna(median_val)\n",
        "        print(f\"Filled NaN in numerical column {col} with median value {median_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4xWUUBuIFK0b",
        "outputId": "9872952c-607e-4c27-e6cd-1fb7b62b2dfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for NaN values before splitting:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Splitting ---\n",
        "print(\"\\n--- Splitting Data into Training and Testing Sets ---\")\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Ensure Driver_ID exists before trying to drop it\n",
        "columns_to_drop_for_X = ['target']\n",
        "if 'Driver_ID' in df_agg.columns:\n",
        "    columns_to_drop_for_X.append('Driver_ID')\n",
        "\n",
        "X = df_agg.drop(columns=columns_to_drop_for_X)\n",
        "y = df_agg['target']\n",
        "\n",
        "\n",
        "# Ensure all feature columns are numeric before proceeding\n",
        "non_numeric_cols = X.select_dtypes(exclude=np.number).columns\n",
        "if len(non_numeric_cols) > 0:\n",
        "    print(f\"Error: Non-numeric columns found in features: {list(non_numeric_cols)}\")\n",
        "    print(\"Please ensure all categorical features are encoded.\")\n",
        "    exit()\n",
        "\n",
        "# Split data into training and testing sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # Stratify by y for imbalance\n",
        "\n",
        "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Testing target distribution:\\n{y_test.value_counts(normalize=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y8whfnWGFP_B",
        "outputId": "b740b1cb-1379-401b-bc4d-57b0440bae39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Splitting Data into Training and Testing Sets ---\n",
            "Training set shape: X_train=(1904, 40), y_train=(1904,)\n",
            "Testing set shape: X_test=(477, 40), y_test=(477,)\n",
            "Training target distribution:\n",
            "target\n",
            "1    0.678571\n",
            "0    0.321429\n",
            "Name: proportion, dtype: float64\n",
            "Testing target distribution:\n",
            "target\n",
            "1    0.679245\n",
            "0    0.320755\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Class Imbalance Treatment (SMOTE) ---\n",
        "print(\"\\n--- Handling Class Imbalance using SMOTE (on training data) ---\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Shape after SMOTE: X_train_resampled={X_train_resampled.shape}, y_train_resampled={y_train_resampled.shape}\")\n",
        "print(f\"Training target distribution after SMOTE:\\n{y_train_resampled.value_counts(normalize=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oQUvcK-TFTiO",
        "outputId": "c2219803-e7f9-47d3-8bec-001da7ee7ede"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Handling Class Imbalance using SMOTE (on training data) ---\n",
            "Shape after SMOTE: X_train_resampled=(2584, 40), y_train_resampled=(2584,)\n",
            "Training target distribution after SMOTE:\n",
            "target\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Standardization ---\n",
        "print(\"\\n--- Standardizing Numerical Features ---\")\n",
        "\n",
        "# Identify numerical columns to scale (should be all columns in X now)\n",
        "# We fit the scaler ONLY on the training data (resampled)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test) # Use the same scaler fitted on training data\n",
        "\n",
        "# Convert scaled arrays back to DataFrames (optional, but can be helpful)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "print(\"Standardization complete.\")\n",
        "print(\"\\nScaled Training Data Head:\")\n",
        "print(X_train_scaled.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8q0MpOsLFYYA",
        "outputId": "91243d07-d550-43a8-bed2-8f72f48878ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Standardizing Numerical Features ---\n",
            "Standardization complete.\n",
            "\n",
            "Scaled Training Data Head:\n",
            "        Age    Gender  Education_Level  Joining Designation  Income_mean  \\\n",
            "0  0.021597  1.255608        -1.147954             1.489580     1.598601   \n",
            "1  1.426191 -0.873650        -1.147954            -0.976195    -0.319129   \n",
            "2 -1.207422 -0.873650         0.116998             0.256693     0.553477   \n",
            "3  0.197172 -0.873650         0.116998            -0.976195     0.345110   \n",
            "4  0.372746 -0.873650        -1.147954             0.256693     1.790012   \n",
            "\n",
            "     Income     Grade  Total Business Value_mean  Total Business Value  \\\n",
            "0  1.588499  1.006710                  -0.720311             -0.270449   \n",
            "1 -0.322971 -1.192224                  -0.720311             -0.270449   \n",
            "2  0.546786 -0.092757                  -0.720311             -0.270449   \n",
            "3  0.339099  1.006710                   1.748135              0.823505   \n",
            "4  1.779285  1.006710                  -0.720311             -0.270449   \n",
            "\n",
            "   Quarterly_Rating_first  ...  City_C27  City_C28  City_C29   City_C3  \\\n",
            "0               -0.564950  ... -0.166865   -0.1693 -0.181035 -0.164399   \n",
            "1               -0.564950  ... -0.166865   -0.1693 -0.181035 -0.164399   \n",
            "2               -0.564950  ... -0.166865   -0.1693 -0.181035 -0.164399   \n",
            "3                0.710012  ... -0.166865   -0.1693 -0.181035 -0.164399   \n",
            "4               -0.564950  ... -0.166865   -0.1693 -0.181035 -0.164399   \n",
            "\n",
            "    City_C4   City_C5   City_C6   City_C7   City_C8   City_C9  \n",
            "0 -0.155491 -0.158083 -0.147471  6.541912 -0.168087 -0.159364  \n",
            "1 -0.155491 -0.158083 -0.147471 -0.152861 -0.168087  6.274950  \n",
            "2 -0.155491 -0.158083 -0.147471 -0.152861 -0.168087 -0.159364  \n",
            "3 -0.155491 -0.158083 -0.147471 -0.152861 -0.168087 -0.159364  \n",
            "4 -0.155491 -0.158083 -0.147471 -0.152861 -0.168087 -0.159364  \n",
            "\n",
            "[5 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Building ---\n",
        "print(\"\\n--- Model Building ---\")\n",
        "\n",
        "# --- Model 1: Random Forest (Bagging) ---\n",
        "print(\"\\nTraining Random Forest Classifier...\")\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced') # Using default parameters + balanced weights\n",
        "\n",
        "# Optional: Hyperparameter Tuning with GridSearchCV (can be time-consuming)\n",
        "# param_grid_rf = {\n",
        "#     'n_estimators': [100, 200],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'min_samples_split': [2, 5]\n",
        "# }\n",
        "# grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'), param_grid_rf, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "# grid_search_rf.fit(X_train_scaled, y_train_resampled)\n",
        "# rf_clf = grid_search_rf.best_estimator_\n",
        "# print(f\"Best RF Params: {grid_search_rf.best_params_}\")\n",
        "\n",
        "rf_clf.fit(X_train_scaled, y_train_resampled)\n",
        "print(\"Random Forest training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R9sFUKZVFauS",
        "outputId": "d1e0bc4f-2f8d-4226-a865-516fb716381b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Building ---\n",
            "\n",
            "Training Random Forest Classifier...\n",
            "Random Forest training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model 2: Gradient Boosting (Boosting) ---\n",
        "print(\"\\nTraining Gradient Boosting Classifier...\")\n",
        "gb_clf = GradientBoostingClassifier(random_state=42, n_estimators=100) # Using default parameters\n",
        "\n",
        "# Optional: Hyperparameter Tuning with GridSearchCV\n",
        "# param_grid_gb = {\n",
        "#     'n_estimators': [100, 200],\n",
        "#     'learning_rate': [0.1, 0.05],\n",
        "#     'max_depth': [3, 5]\n",
        "# }\n",
        "# grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gb, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "# grid_search_gb.fit(X_train_scaled, y_train_resampled)\n",
        "# gb_clf = grid_search_gb.best_estimator_\n",
        "# print(f\"Best GB Params: {grid_search_gb.best_params_}\")\n",
        "\n",
        "gb_clf.fit(X_train_scaled, y_train_resampled)\n",
        "print(\"Gradient Boosting training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tO3JmZMfFg3p",
        "outputId": "47327a69-9ef9-4a27-c60b-1028446b2b3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Gradient Boosting Classifier...\n",
            "Gradient Boosting training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Results Evaluation ---\n",
        "print(\"\\n--- Results Evaluation ---\")\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred_rf = rf_clf.predict(X_test_scaled)\n",
        "y_prob_rf = rf_clf.predict_proba(X_test_scaled)[:, 1] # Probabilities for ROC AUC\n",
        "\n",
        "y_pred_gb = gb_clf.predict(X_test_scaled)\n",
        "y_prob_gb = gb_clf.predict_proba(X_test_scaled)[:, 1] # Probabilities for ROC AUC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IHPnOG4ZFhvi",
        "outputId": "96f877ba-66b1-4da4-c4fb-54b54db199bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Results Evaluation ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation Metrics ---\n",
        "\n",
        "# Random Forest\n",
        "print(\"\\n--- Random Forest Evaluation ---\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
        "print(f\"ROC AUC Score: {roc_auc_rf:.4f}\")\n",
        "\n",
        "# Gradient Boosting\n",
        "print(\"\\n--- Gradient Boosting Evaluation ---\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_gb))\n",
        "roc_auc_gb = roc_auc_score(y_test, y_prob_gb)\n",
        "print(f\"ROC AUC Score: {roc_auc_gb:.4f}\")\n",
        "\n",
        "# --- ROC Curve Data (for potential plotting) ---\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
        "fpr_gb, tpr_gb, _ = roc_curve(y_test, y_prob_gb)\n",
        "\n",
        "# Plot ROC Curve and save to file\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.4f})')\n",
        "plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {roc_auc_gb:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Chance') # Diagonal line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Ola Driver Attrition')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('roc_curve.png')\n",
        "print(\"\\nROC curve saved to roc_curve.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fD153XCtFkXn",
        "outputId": "d06df84a-d6c9-4c4b-8e09-eb26497c43ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest Evaluation ---\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92       153\n",
            "           1       0.97      0.96      0.96       324\n",
            "\n",
            "    accuracy                           0.95       477\n",
            "   macro avg       0.94      0.94      0.94       477\n",
            "weighted avg       0.95      0.95      0.95       477\n",
            "\n",
            "Confusion Matrix:\n",
            "[[142  11]\n",
            " [ 13 311]]\n",
            "ROC AUC Score: 0.9770\n",
            "\n",
            "--- Gradient Boosting Evaluation ---\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93       153\n",
            "           1       0.97      0.96      0.96       324\n",
            "\n",
            "    accuracy                           0.95       477\n",
            "   macro avg       0.94      0.95      0.94       477\n",
            "weighted avg       0.95      0.95      0.95       477\n",
            "\n",
            "Confusion Matrix:\n",
            "[[143  10]\n",
            " [ 13 311]]\n",
            "ROC AUC Score: 0.9811\n",
            "\n",
            "ROC curve saved to roc_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Feature Importance (Example for Random Forest) ---\n",
        "print(\"\\n--- Feature Importance (Random Forest) ---\")\n",
        "try:\n",
        "    feature_importances = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': rf_clf.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(\"Top 10 Features (Random Forest):\")\n",
        "    print(feature_importances.head(10))\n",
        "except AttributeError:\n",
        "    print(\"Could not retrieve feature importances for Random Forest.\")\n",
        "\n",
        "# --- Feature Importance (Example for Gradient Boosting) ---\n",
        "print(\"\\n--- Feature Importance (Gradient Boosting) ---\")\n",
        "try:\n",
        "    feature_importances_gb = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': gb_clf.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(\"Top 10 Features (Gradient Boosting):\")\n",
        "    print(feature_importances_gb.head(10))\n",
        "except AttributeError:\n",
        "    print(\"Could not retrieve feature importances for Gradient Boosting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "crFb41GvFwZW",
        "outputId": "6112730e-bdfe-4bbd-9250-4424fb532aac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Feature Importance (Random Forest) ---\n",
            "Top 10 Features (Random Forest):\n",
            "                      feature  importance\n",
            "11                tenure_days    0.403484\n",
            "8        Total Business Value    0.190034\n",
            "10           Quarterly Rating    0.088285\n",
            "7   Total Business Value_mean    0.084040\n",
            "4                 Income_mean    0.037928\n",
            "5                      Income    0.037823\n",
            "0                         Age    0.032485\n",
            "1                      Gender    0.029033\n",
            "9      Quarterly_Rating_first    0.013934\n",
            "2             Education_Level    0.012983\n",
            "\n",
            "--- Feature Importance (Gradient Boosting) ---\n",
            "Top 10 Features (Gradient Boosting):\n",
            "                      feature  importance\n",
            "11                tenure_days    0.461960\n",
            "8        Total Business Value    0.434459\n",
            "7   Total Business Value_mean    0.065188\n",
            "10           Quarterly Rating    0.009455\n",
            "0                         Age    0.006926\n",
            "1                      Gender    0.005044\n",
            "29                   City_C26    0.002224\n",
            "4                 Income_mean    0.002208\n",
            "6                       Grade    0.002126\n",
            "3         Joining Designation    0.001819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Actionable Insights & Recommendations ---\n",
        "print(\"\\n--- Actionable Insights & Recommendations ---\")\n",
        "print(\"Based on the final model results and feature importances:\")\n",
        "print(\"1. Dominant Predictors: Driver tenure ('tenure_days') and the most recent month's 'Total Business Value' are overwhelmingly the most significant predictors of attrition.\")\n",
        "print(\"2. High Predictive Power: Both Random Forest and Gradient Boosting models achieved excellent performance (AUC ~0.98), indicating a strong ability to identify drivers at risk of leaving.\")\n",
        "print(\"3. Retention Strategy - Tenure Milestones: Implement targeted engagement strategies based on tenure. Drivers might be more prone to leaving at specific points (e.g., early tenure, after 1 year). Recognize and reward loyalty at key milestones.\")\n",
        "print(\"4. Retention Strategy - Business Value Monitoring: Closely monitor drivers with low or declining 'Total Business Value'. Investigate the root causes (e.g., low ride volume, high cancellations/refunds, EMI issues) and offer targeted support or incentives.\")\n",
        "print(\"5. Secondary Factors: While less dominant, factors like 'Quarterly Rating', 'Income', and 'Age' still play a role. Continue monitoring these, especially sudden drops in rating or income.\")\n",
        "print(\"6. Model Utility: The high accuracy suggests these models can be effectively deployed to proactively identify at-risk drivers, allowing for timely intervention.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Analysis Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jw47ewTmF0TK",
        "outputId": "9581cfe8-1610-45ef-a98e-1293d2b51120"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Actionable Insights & Recommendations ---\n",
            "Based on the final model results and feature importances:\n",
            "1. Dominant Predictors: Driver tenure ('tenure_days') and the most recent month's 'Total Business Value' are overwhelmingly the most significant predictors of attrition.\n",
            "2. High Predictive Power: Both Random Forest and Gradient Boosting models achieved excellent performance (AUC ~0.98), indicating a strong ability to identify drivers at risk of leaving.\n",
            "3. Retention Strategy - Tenure Milestones: Implement targeted engagement strategies based on tenure. Drivers might be more prone to leaving at specific points (e.g., early tenure, after 1 year). Recognize and reward loyalty at key milestones.\n",
            "4. Retention Strategy - Business Value Monitoring: Closely monitor drivers with low or declining 'Total Business Value'. Investigate the root causes (e.g., low ride volume, high cancellations/refunds, EMI issues) and offer targeted support or incentives.\n",
            "5. Secondary Factors: While less dominant, factors like 'Quarterly Rating', 'Income', and 'Age' still play a role. Continue monitoring these, especially sudden drops in rating or income.\n",
            "6. Model Utility: The high accuracy suggests these models can be effectively deployed to proactively identify at-risk drivers, allowing for timely intervention.\n",
            "\n",
            "--- Analysis Complete ---\n"
          ]
        }
      ]
    }
  ]
}